import streamlit as st
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableParallel

from src import config, data_loader, vector_store, llm

def format_docs(docs):
    """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ í”„ë¡¬í”„íŠ¸ì— ì‚½ì…í•  ë¬¸ìì—´ë¡œ í¬ë§·í•©ë‹ˆë‹¤."""
    return "\n\n".join(doc.page_content for doc in docs)

@st.cache_resource
def get_rag_chain_with_source():
    """
    ë‹µë³€ê³¼ ì¶œì²˜ë¥¼ í•¨ê»˜ ë°˜í™˜í•˜ëŠ” RAG ì²´ì¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    Streamlitì˜ ìºì‹œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ë¦¬ì†ŒìŠ¤ë¥¼ í•œ ë²ˆë§Œ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    # 1. ë°ì´í„° ë¡œë“œ ë° ë¶„í• 
    docs = data_loader.load_all_documents()
    if not docs:
        return None
    splits = data_loader.split_documents(docs)

    # 2. ì„ë² ë”© ë° ë²¡í„° ì €ì¥ì†Œ ìƒì„±
    embeddings = vector_store.get_embedding_model()
    db = vector_store.build_vector_store(splits, embeddings)
    retriever = db.as_retriever(search_kwargs={"k": 6})

    # 3. LLM ì¸ìŠ¤í„´ìŠ¤í™”
    llm_instance = llm.get_llm()

    # 4. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
    template = """
"ë‹¹ì‹ ì€ í•œêµ­ ë²•ë ¹ ë¦¬ì„œì²˜ì…ë‹ˆë‹¤. ì•„ë˜ <ì»¨í…ìŠ¤íŠ¸>ë§Œì„ ê·¼ê±°ë¡œ "
"ê°„ê²°í•˜ê³  ì •í™•íˆ ë‹µë³€í•˜ê³ , ì¸ìš©(ì œëª©/ì¶œì²˜)ì„ ì œì‹œí•˜ì„¸ìš”. "
"ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ì„¸ìš”."

<ì»¨í…ìŠ¤íŠ¸>
{context}

[ì§ˆë¬¸]
{question}

í˜•ì‹:
- ìš”ì•½(2~5ë¬¸ì¥)
- í•µì‹¬í¬ì¸íŠ¸(ë¶ˆë¦¿)
- ì¸ìš©(ì œëª©/ì¶œì²˜)
- ë©´ì±…ê³ ì§€

ìµœì¢… ë‹µë§Œ í•œêµ­ì–´ë¡œ. ì‚¬ê³ íë¦„/ë©”íƒ€ ê¸ˆì§€.
"""
    prompt = PromptTemplate.from_template(template)

    # 5. LCELì„ ì‚¬ìš©í•œ RAG ì²´ì¸ êµ¬ì„± (ì¶œì²˜ í¬í•¨)
    
    # ë‹µë³€ ìƒì„± ë¶€ë¶„
    rag_chain_from_docs = (
        RunnablePassthrough.assign(context=(lambda x: format_docs(x["context"])))
        | prompt
        | llm_instance
        | StrOutputParser()
    )

    # ì¶œì²˜(context)ì™€ ì§ˆë¬¸(question)ì„ ë°›ê³ , ë‹µë³€(answer)ì„ ìƒì„±í•˜ì—¬ í•¨ê»˜ ë°˜í™˜
    rag_chain_with_source = RunnableParallel(
        {"context": retriever, "question": RunnablePassthrough()}
    ).assign(answer=rag_chain_from_docs)
    
    return rag_chain_with_source

# --- Streamlit UI êµ¬ì„± ---

st.title("ë²•ë¥  RAG Q&A ì‹œìŠ¤í…œ")
st.markdown("---")

# RAG ì²´ì¸ ë¡œë“œ
rag_chain = get_rag_chain_with_source()

if rag_chain is None:
    st.error(f"âš ï¸  ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. '{config.DATA_DIR}' ë””ë ‰í† ë¦¬ì— .txt ë˜ëŠ” .pdf íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
else:
    # ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
    query = st.text_input(
        "ê¶ê¸ˆí•œ ë²•ë¥  ì •ë³´ë¥¼ ì§ˆë¬¸í•˜ì„¸ìš”:",
        placeholder="ì˜ˆ: ê·¼ë¡œê¸°ì¤€ë²•ìƒ ì—°ì°¨ ìœ ê¸‰íœ´ê°€ì— ëŒ€í•´ ì•Œë ¤ì¤˜"
    )

    if st.button("ì§ˆë¬¸í•˜ê¸°"):
        if query:
            with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    # ì²´ì¸ ì‹¤í–‰ (ê²°ê³¼ì— 'answer'ì™€ 'context' í¬í•¨)
                    result = rag_chain.invoke(query)

                    st.markdown("#### ë‹µë³€")
                    st.markdown(result["answer"].strip())
                    
                    # ë‹µë³€ ê·¼ê±° (ì¶œì²˜) í‘œì‹œ
                    st.markdown("---")
                    with st.expander("ğŸ“‚ ë‹µë³€ ê·¼ê±° ë³´ê¸°"):
                        for doc in result["context"]:
                            st.markdown(f"**[ì¶œì²˜: {doc.metadata.get('source', 'N/A')}]**")
                            st.markdown(doc.page_content)
                            st.markdown("---")

                except Exception as e:
                    st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        else:
            st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
